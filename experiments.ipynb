{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instance():\n",
    "    T = 100000\n",
    "    N = 6\n",
    "    d = 20\n",
    "    mu_noise_level = 0.1\n",
    "    reward_noise_level = 0.1\n",
    "    covariate_diversity=True\n",
    "    \n",
    "    mu_true = np.random.randn(N,d)\n",
    "    contexts = get_contexts(d,T,covariate_diversity)\n",
    "\n",
    "    return {'T':T,'N':N,'d':d,'mu_noise_level':mu_noise_level,\n",
    "          'reward_noise_level':reward_noise_level,\n",
    "         'mu_true':mu_true,'contexts':contexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_noise(d,mu_noise_level=0.5):\n",
    "    '''noise in the mu true vectors'''\n",
    "    return mu_noise_level*np.random.randn(d)\n",
    "\n",
    "def reward_noise(reward_noise_level=0.1):\n",
    "    '''noise in the reward signal'''\n",
    "    return reward_noise_level*np.random.randn()\n",
    "\n",
    "def get_choice_myopic(context,mu_x,payments=None):\n",
    "    '''agents are myopic but deterministic. tbd: stochastic'''\n",
    "    temp = np.dot(mu_x,context)\n",
    "    if payments is not None:\n",
    "        temp += payments\n",
    "    return temp.argmax()\n",
    "\n",
    "def get_contexts(d,T,covariate_diversity=True):\n",
    "    '''pre-generated contexts'''\n",
    "    contexts = {}\n",
    "    if covariate_diversity is True:\n",
    "        for t in range(T):\n",
    "            contexts[t] = np.random.randn(d)\n",
    "        return contexts\n",
    "    else:\n",
    "        mean = np.ones(d)\n",
    "        cov0 = 0.1*np.random.randn(d,d)\n",
    "        cov = np.ones((d,d)) + np.dot(cov0,cov0.transpose())\n",
    "\n",
    "        for t in range(T):\n",
    "            contexts[t] = np.random.multivariate_normal(mean, cov)\n",
    "        return contexts    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactions(instance,get_payments):\n",
    "\n",
    "    mu_true = instance['mu_true']\n",
    "    N = instance['N']\n",
    "    d = instance['d']\n",
    "    mu_noise_level = instance['mu_noise_level']\n",
    "    T = instance['T']\n",
    "    contexts = instance['contexts']\n",
    "    \n",
    "    #Initial N rounds are free\n",
    "    mu_estimated = np.zeros_like(mu_true)\n",
    "    for t in range(N):\n",
    "        mu_estimated[t] = mu_true[t] + mu_noise(d,mu_noise_level)\n",
    "\n",
    "    #variables for logging\n",
    "    pseudoregret_inst = np.zeros(T)\n",
    "    history = {}\n",
    "\n",
    "    #T interactions\n",
    "    for t in range(T):\n",
    "        #agent arrives\n",
    "        context = contexts[t]\n",
    "\n",
    "        #platform decides to pay\n",
    "        payments = get_payments(context,contexts,history,t,T,N,mu_estimated)\n",
    "\n",
    "        #agent decides arm and information is revealed\n",
    "        choice = get_choice_myopic(context,mu_estimated,payments)\n",
    "        mu_realized = mu_true[choice] + mu_noise(d,mu_noise_level)\n",
    "        reward_realized = np.dot(mu_true[choice],context) + reward_noise()\n",
    "\n",
    "        #Platform updates estimates\n",
    "        mu_estimated[choice] = (t*mu_estimated[choice] + mu_realized)/(t+1)\n",
    "\n",
    "        #Regret computation\n",
    "        opt_choice = get_choice_myopic(context,mu_true,None)\n",
    "        pseudoregret_inst[t] = np.dot(mu_true[opt_choice] - mu_true[choice],context)\n",
    "\n",
    "        #History\n",
    "        history[t] = {'choice':choice,'payments':payments,'mu_realized':mu_realized}\n",
    "\n",
    "    assert pseudoregret_inst.min() >= 0\n",
    "    pseudoregret = np.cumsum(pseudoregret_inst)\n",
    "    return pseudoregret,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_payments_none(context,contexts,history,t,T,N,mu_estimated):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_payments_iehu(context,contexts,history,t,T,N,mu_estimated):\n",
    "    \n",
    "    #count of arm pulls\n",
    "    arm_pulls = np.zeros(N)\n",
    "    for x in history:\n",
    "        arm_pulls[history[x]['choice']] += 1\n",
    "    \n",
    "    #phase estimate\n",
    "    s = arm_pulls.min()+1 #plus 1 because of the initial N pulls\n",
    "\n",
    "    #payment eligible arm estimation\n",
    "    phivec = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for k in range(t):\n",
    "            constraint_holds = True\n",
    "            for j in range(N):\n",
    "                if i != j:\n",
    "                    if np.dot(contexts[k],mu_estimated[i]-mu_estimated[j]) <= 0:\n",
    "                        constraint_holds = False\n",
    "            if constraint_holds == True:\n",
    "                phivec[i] += 1\n",
    "    phivec = phivec/phivec.sum()            \n",
    "    \n",
    "    if phivec.min() > 1/np.log(s+1e-6):\n",
    "        return None #no payment\n",
    "    else:\n",
    "        #estimating payment amount\n",
    "        peligible_arm = phivec.argmin()\n",
    "        \n",
    "        largest = 0\n",
    "        for i in range(N):\n",
    "            if i != peligible_arm:\n",
    "                temp = np.dot(context,mu_estimated[i] - mu_estimated[peligible_arm])\n",
    "                if temp > largest:\n",
    "                    largest = temp\n",
    "\n",
    "        payment = np.zeros(N)\n",
    "        payment[peligible_arm] = largest\n",
    "#         print('t',t,'payment',largest)\n",
    "        return payment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mc_runs = 5\n",
    "algos = {'greedy':get_payments_none}\n",
    "# algos = {'iehu':get_payments_iehu}\n",
    "# algos = {'greedy':get_payments_none, 'iehu':get_payments_iehu}\n",
    "prs_all = {}\n",
    "history_all = {}\n",
    "for algo in algos:\n",
    "    prs_all[algo] = [0]*n_mc_runs\n",
    "    history_all[algo] = {}\n",
    "instance = {}\n",
    "for mc_run in range(n_mc_runs):\n",
    "    instance[mc_run] = generate_instance()\n",
    "    for algo in algos:\n",
    "        prs_all[algo][mc_run],history_all[algo][mc_run] = interactions(instance = instance[mc_run],get_payments = algos[algo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,algo in enumerate(algos):\n",
    "    plt.figure()\n",
    "    print(algo)\n",
    "    plt.plot(np.mean(prs_all[algo],axis=0),label=algo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [history_all['greedy'][0][x]['choice'] for x in history_all['greedy'][0]]\n",
    "# b = [history_all['iehu'][0][x]['choice'] for x in history_all['iehu'][0]]\n",
    "# [x for x in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
